{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JUSTIN V GEORGE\n",
    "ROLL NO : 09\n",
    "S7 CSE B - YOP'2024\n",
    "Amal Jyothi College of Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AI ASSIGNMENT 3\n",
    "Question -> Create a video of executing any small AI application code with your own audio explanation of code and its running features.\n",
    "Your face should be visible in the video while explaining the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_nlp in c:\\users\\justi\\anaconda3\\lib\\site-packages (0.7.0)\n",
      "Requirement already satisfied: rich in c:\\users\\justi\\anaconda3\\lib\\site-packages (from keras_nlp) (13.7.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\justi\\anaconda3\\lib\\site-packages (from keras_nlp) (1.4.0)\n",
      "Requirement already satisfied: tensorflow-text in c:\\users\\justi\\anaconda3\\lib\\site-packages (from keras_nlp) (2.10.0)\n",
      "Requirement already satisfied: keras-core in c:\\users\\justi\\anaconda3\\lib\\site-packages (from keras_nlp) (0.1.7)\n",
      "Requirement already satisfied: packaging in c:\\users\\justi\\anaconda3\\lib\\site-packages (from keras_nlp) (23.0)\n",
      "Requirement already satisfied: regex in c:\\users\\justi\\anaconda3\\lib\\site-packages (from keras_nlp) (2023.3.23)\n",
      "Requirement already satisfied: numpy in c:\\users\\justi\\anaconda3\\lib\\site-packages (from keras_nlp) (1.23.5)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\justi\\anaconda3\\lib\\site-packages (from keras_nlp) (0.1.8)\n",
      "Requirement already satisfied: namex in c:\\users\\justi\\anaconda3\\lib\\site-packages (from keras-core->keras_nlp) (0.0.7)\n",
      "Requirement already satisfied: h5py in c:\\users\\justi\\anaconda3\\lib\\site-packages (from keras-core->keras_nlp) (3.8.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from rich->keras_nlp) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from rich->keras_nlp) (2.14.0)\n",
      "Requirement already satisfied: tensorflow<2.11,>=2.10.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow-text->keras_nlp) (2.10.1)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow-text->keras_nlp) (0.15.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras_nlp) (0.1.2)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (2.10.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (4.5.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (23.1.21)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (1.15.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (1.16.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (0.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (2.10.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (0.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (67.6.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (3.19.6)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (2.10.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (2.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (1.51.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (15.0.6.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (0.30.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (0.40.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (3.4.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (2.28.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (2.3.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (2.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (0.2.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (6.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (2.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\justi\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow<2.11,>=2.10.0->tensorflow-text->keras_nlp) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3060 Laptop GPU, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # \"jax\" or \"tensorflow\" or \"torch\"\n",
    "\n",
    "import keras_nlp\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Load a pre-trained GPT-2 model and generate some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To speed up training and generation -> here we use preprocessor of length 128 instead of full length 1024.\n",
    "preprocessor = keras_nlp.models.GPT2CausalLMPreprocessor.from_preset(\n",
    "    \"gpt2_base_en\",\n",
    "    sequence_length=128,\n",
    ")\n",
    "gpt2_lm = keras_nlp.models.GPT2CausalLM.from_preset(\n",
    "    \"gpt2_base_en\", preprocessor=preprocessor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPT-2 output:\n",
      "My trip to Yosemite was a great experience. The first time I went was at the beginning of June when the sun went down and I was sitting on the top of a rock. The sun was shining through the window as I watched the snow falling. I thought about the snow, how it would affect the snow. The sun was shining and I thought I was in the middle of the snow. The next day was a bit colder. I was sitting on a ledge on the edge of the rock. The sun was setting and I saw a white cloud over the horizon. It was a cloud of ice. I thought to myself, \"What a strange thing that is. What a beautiful thing that is.\"\n",
      "\n",
      "It took a few days to get to Yosemite and then I got to my car and headed out to Yosemite.\n",
      "\n",
      "I was very impressed with the scenery. I was very pleased with the way it looked on the road as I was driving through the park. I was very pleased\n",
      "TOTAL TIME ELAPSED: 15.62s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "output = gpt2_lm.generate(\"My trip to Yosemite was\", max_length=200)\n",
    "print(\"\\nGPT-2 output:\")\n",
    "print(output)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPT-2 output:\n",
      "My college is  a very small college and I have been doing a lot of research about how to make my college a safe place for me to work.  I have been doing a lot of research about how to make my college a safe place for me to work.  I have been doing a lot of research about how to make my college a safe place for me to work.  I have been doing a lot of research about how to make my college a safe place for me to work.  I have been doing a lot of research about how to make my college a safe place for me to\n",
      "TOTAL TIME ELAPSED: 0.95s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "output = gpt2_lm.generate(\"My college is \", max_length=200)\n",
    "print(\"\\nGPT-2 output:\")\n",
    "print(output)\n",
    "\n",
    "end = time.time()\n",
    "print(f\"TOTAL TIME ELAPSED: {end - start:.2f}s\")\n",
    "# Second call is faster as the computational graph is XLA compiled in the 1st run and re-used in the 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KerasNLP offers a few sampling methods, like contrastive search, Top-K and beam sampling.\n",
    "\n",
    "By default, \"GPT2CausalLM uses Top-k search\", but we can choose our own sampling method.\n",
    "\n",
    "There are 'two ways' to specify our custom sampler:\n",
    "*Use a string identifier, such as \"greedy\", -> the default configuration .\n",
    "*Pass a \"keras_nlp.samplers.Sampler\" instance, -> custom configuration ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GPT-2 output:\n",
      "I like basketball, but I like the game more because I like the way it's played and how it plays.\n",
      "\n",
      "You've got to have a good shot, but you also have to have a good team to play with.\n",
      "\n",
      "It's hard to be the best player in the NBA. I'm going to try and get better, so I'm going to try my best to do it. I want to win, and I know I have that in my back pocket.\n",
      "\n",
      "So I want to win, and I want to win, and I know that I can play well. So that's the way it works.\n",
      "\n",
      "I'm going to play hard, but I want to play with a great mindset, a great attitude.\n",
      "\n",
      "I'm going to play hard, but I also like to have a great mindset. I like to play hard, but you also have to have a great mindset to play.\n",
      "\n",
      "It's not about the score, but\n",
      "WARNING:tensorflow:5 out of the last 6 calls to <bound method GPT2CausalLM.generate_step of <keras_nlp.models.gpt2.gpt2_causal_lm.GPT2CausalLM object at 0x0000021FDF18C790>> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "GPT-2 output:\n",
      "I like basketball. I like to play it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to watch it. I like to\n"
     ]
    }
   ],
   "source": [
    "# Use a string identifier.\n",
    "gpt2_lm.compile(sampler=\"top_k\")\n",
    "output = gpt2_lm.generate(\"I like basketball\", max_length=200)\n",
    "print(\"\\nGPT-2 output:\")\n",
    "print(output)\n",
    "\n",
    "# Use a `Sampler` instance. eg: `GreedySampler` -> tends to repeat itself,\n",
    "greedy_sampler = keras_nlp.samplers.GreedySampler()\n",
    "gpt2_lm.compile(sampler=greedy_sampler)\n",
    "\n",
    "output = gpt2_lm.generate(\"I like basketball\", max_length=200)\n",
    "print(\"\\nGPT-2 output:\")\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
